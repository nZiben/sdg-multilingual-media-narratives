{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SDG Multilingual Media Narratives — Notebook 00: Setup & Project Config\n",
        "\n",
        "This notebook sets up a lightweight, reproducible folder structure, environment checks, and shared configuration.\n",
        "\n",
        "**Project context:** derived from your document “Cross-Cultural Media Narratives: A Multilingual Analysis of SDG Coverage”. fileciteturn0file0\n",
        "\n",
        "> Notes\n",
        "- These notebooks are written to run without paid APIs. GDELT is used as a public source.\n",
        "- Social media APIs (X/Twitter, Weibo, etc.) are left as placeholders because access varies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
            "Platform: macOS-15.5-arm64-arm-64bit-Mach-O\n",
            "Pandas: 2.3.3\n"
          ]
        }
      ],
      "source": [
        "import os, sys, platform\n",
        "import pandas as pd\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('Pandas:', pd.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created/checked folders:\n",
            " - /Users/sergey/code/sdg-multilingual-media-narratives/data\n",
            " - /Users/sergey/code/sdg-multilingual-media-narratives/data/raw\n",
            " - /Users/sergey/code/sdg-multilingual-media-narratives/data/processed\n",
            " - /Users/sergey/code/sdg-multilingual-media-narratives/figures\n",
            " - /Users/sergey/code/sdg-multilingual-media-narratives/reports\n"
          ]
        }
      ],
      "source": [
        "PROJECT_DIR = os.path.abspath('.')\n",
        "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
        "RAW_DIR = os.path.join(DATA_DIR, 'raw')\n",
        "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
        "FIG_DIR = os.path.join(PROJECT_DIR, 'figures')\n",
        "REPORTS_DIR = os.path.join(PROJECT_DIR, 'reports')\n",
        "\n",
        "for d in [DATA_DIR, RAW_DIR, PROCESSED_DIR, FIG_DIR, REPORTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print('Created/checked folders:')\n",
        "for d in [DATA_DIR, RAW_DIR, PROCESSED_DIR, FIG_DIR, REPORTS_DIR]:\n",
        "    print(' -', d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shared helpers\n",
        "We define a few helper functions used by later notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import hashlib\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def sha1_text(s: str) -> str:\n",
        "    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
        "\n",
        "def ensure_dir(path: str) -> None:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def now_utc_iso() -> str:\n",
        "    import datetime\n",
        "    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
        "\n",
        "def safe_get(d: dict, *keys, default=None):\n",
        "    cur = d\n",
        "    for k in keys:\n",
        "        if not isinstance(cur, dict) or k not in cur:\n",
        "            return default\n",
        "        cur = cur[k]\n",
        "    return cur\n",
        "\n",
        "def normalize_whitespace(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.replace(\"\\u00a0\", \" \")\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def parse_gdelt_date(date_str: str):\n",
        "    # GDELT often returns YYYYMMDDHHMMSS\n",
        "    if not isinstance(date_str, str):\n",
        "        return pd.NaT\n",
        "    if re.fullmatch(r\"\\d{14}\", date_str):\n",
        "        return pd.to_datetime(date_str, format=\"%Y%m%d%H%M%S\", errors=\"coerce\", utc=True)\n",
        "    # fallback\n",
        "    return pd.to_datetime(date_str, errors=\"coerce\", utc=True)\n",
        "\n",
        "def language_bucket(lang: str) -> str:\n",
        "    # normalize a few common labels\n",
        "    if not isinstance(lang, str) or not lang:\n",
        "        return \"unknown\"\n",
        "    lang = lang.lower()\n",
        "    mapping = {\n",
        "        \"zh-cn\": \"zh\",\n",
        "        \"zh-tw\": \"zh\",\n",
        "        \"zh-hk\": \"zh\",\n",
        "        \"zh\": \"zh\",\n",
        "        \"en\": \"en\",\n",
        "        \"es\": \"es\",\n",
        "        \"ru\": \"ru\",\n",
        "    }\n",
        "    return mapping.get(lang, lang)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote /Users/sergey/code/sdg-multilingual-media-narratives/sdg_helpers.py\n"
          ]
        }
      ],
      "source": [
        "# Save helpers to a local python module so later notebooks can import it.\n",
        "helpers_path = os.path.join(PROJECT_DIR, 'sdg_helpers.py')\n",
        "with open(helpers_path, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\nimport os\\nimport re\\nimport json\\nimport time\\nimport math\\nimport hashlib\\nfrom dataclasses import dataclass\\nfrom typing import Dict, List, Optional, Tuple\\n\\nimport pandas as pd\\nimport numpy as np\\n\\ndef sha1_text(s: str) -> str:\\n    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\\n\\ndef ensure_dir(path: str) -> None:\\n    os.makedirs(path, exist_ok=True)\\n\\ndef now_utc_iso() -> str:\\n    import datetime\\n    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\\n\\ndef safe_get(d: dict, *keys, default=None):\\n    cur = d\\n    for k in keys:\\n        if not isinstance(cur, dict) or k not in cur:\\n            return default\\n        cur = cur[k]\\n    return cur\\n\\ndef normalize_whitespace(text: str) -> str:\\n    if not isinstance(text, str):\\n        return \"\"\\n    text = text.replace(\"\\\\u00a0\", \" \")\\n    text = re.sub(r\"\\\\s+\", \" \", text).strip()\\n    return text\\n\\ndef parse_gdelt_date(date_str: str):\\n    # GDELT often returns YYYYMMDDHHMMSS\\n    if not isinstance(date_str, str):\\n        return pd.NaT\\n    if re.fullmatch(r\"\\\\d{14}\", date_str):\\n        return pd.to_datetime(date_str, format=\"%Y%m%d%H%M%S\", errors=\"coerce\", utc=True)\\n    # fallback\\n    return pd.to_datetime(date_str, errors=\"coerce\", utc=True)\\n\\ndef language_bucket(lang: str) -> str:\\n    # normalize a few common labels\\n    if not isinstance(lang, str) or not lang:\\n        return \"unknown\"\\n    lang = lang.lower()\\n    mapping = {\\n        \"zh-cn\": \"zh\",\\n        \"zh-tw\": \"zh\",\\n        \"zh-hk\": \"zh\",\\n        \"zh\": \"zh\",\\n        \"en\": \"en\",\\n        \"es\": \"es\",\\n        \"ru\": \"ru\",\\n    }\\n    return mapping.get(lang, lang)\\n')\n",
        "print('Wrote', helpers_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parquet I/O (pyarrow-first)\n",
        "\n",
        "On some Python 3.13 + pandas/pyarrow combos, `pd.read_parquet()` / `df.to_parquet()` can fail\n",
        "due to Arrow extension-type registry issues. We therefore use **pyarrow** read/write helpers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "\n",
        "def write_parquet(df: pd.DataFrame, path: str, compression: str = \"snappy\") -> None:\n",
        "    \"\"\"Write parquet via pyarrow (avoids pandas' parquet engine registry issues).\"\"\"\n",
        "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
        "    try:\n",
        "        pq.write_table(table, path, compression=compression)\n",
        "    except Exception:\n",
        "        # If compression codec not available, write uncompressed.\n",
        "        pq.write_table(table, path, compression=None)\n",
        "\n",
        "def read_parquet(path: str) -> pd.DataFrame:\n",
        "    \"\"\"Read parquet via pyarrow and return pandas DataFrame.\"\"\"\n",
        "    return pq.read_table(path).to_pandas()\n",
        "\n",
        "# Save these helpers to a module for other notebooks.\n",
        "parquet_path = os.path.join(os.path.abspath(\".\"), \"sdg_parquet.py\")\n",
        "with open(parquet_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\n",
        "        \"import pyarrow as pa\\n\"\n",
        "        \"import pyarrow.parquet as pq\\n\"\n",
        "        \"import pandas as pd\\n\\n\"\n",
        "        \"def write_parquet(df: pd.DataFrame, path: str, compression: str = 'snappy') -> None:\\n\"\n",
        "        \"    table = pa.Table.from_pandas(df, preserve_index=False)\\n\"\n",
        "        \"    try:\\n\"\n",
        "        \"        pq.write_table(table, path, compression=compression)\\n\"\n",
        "        \"    except Exception:\\n\"\n",
        "        \"        pq.write_table(table, path, compression=None)\\n\\n\"\n",
        "        \"def read_parquet(path: str) -> pd.DataFrame:\\n\"\n",
        "        \"    return pq.read_table(path).to_pandas()\\n\"\n",
        "    )\n",
        "print(\"Wrote\", parquet_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keywords (starter)\n",
        "Keyword tagging is a **baseline** (weak supervision). You can replace with a multilingual classifier later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Minimal starter keyword sets (extend as you like).\n",
        "# IMPORTANT: keyword lists are imperfect; treat as weak supervision.\n",
        "SDG_KEYWORDS = {\n",
        "    \"SDG1_No_Poverty\": [\"poverty\", \"poor\", \"low-income\", \"homeless\", \"соцзащита\", \"бедност\", \"贫困\", \"pobreza\"],\n",
        "    \"SDG2_Zero_Hunger\": [\"hunger\", \"food security\", \"malnutrition\", \"famine\", \"голод\", \"饥饿\", \"hambre\"],\n",
        "    \"SDG3_Good_Health\": [\"health\", \"pandemic\", \"hospital\", \"vaccine\", \"well-being\", \"covid\", \"здоров\", \"疫苗\", \"salud\"],\n",
        "    \"SDG4_Quality_Education\": [\"education\", \"school\", \"university\", \"literacy\", \"образован\", \"教育\", \"educación\"],\n",
        "    \"SDG5_Gender_Equality\": [\"gender\", \"women\", \"girls\", \"equality\", \"femin\", \"гендер\", \"妇女\", \"igualdad de género\"],\n",
        "    \"SDG6_Clean_Water\": [\"water\", \"sanitation\", \"wastewater\", \"clean drinking\", \"вода\", \"卫生\", \"agua potable\"],\n",
        "    \"SDG7_Clean_Energy\": [\"renewable\", \"solar\", \"wind power\", \"clean energy\", \"能源转型\", \"возобновляем\", \"energía renovable\"],\n",
        "    \"SDG8_Decent_Work\": [\"jobs\", \"employment\", \"labor\", \"wages\", \"economic growth\", \"занятость\", \"就业\", \"empleo\"],\n",
        "    \"SDG9_Industry_Innovation\": [\"innovation\", \"infrastructure\", \"industry\", \"technology\", \"инфраструктур\", \"创新\", \"infraestructura\"],\n",
        "    \"SDG10_Reduced_Inequalities\": [\"inequality\", \"inequalities\", \"migration\", \"minorities\", \"неравенств\", \"不平等\", \"desigualdad\"],\n",
        "    \"SDG11_Sustainable_Cities\": [\"cities\", \"urban\", \"housing\", \"transport\", \"resilience\", \"город\", \"城市\", \"ciudades sostenibles\"],\n",
        "    \"SDG12_Responsible_Consumption\": [\"recycling\", \"waste\", \"circular economy\", \"consumption\", \"отход\", \"循环经济\", \"consumo responsable\"],\n",
        "    \"SDG13_Climate_Action\": [\"climate change\", \"global warming\", \"carbon emissions\", \"net zero\", \"парников\", \"气候变化\", \"cambio climático\"],\n",
        "    \"SDG14_Life_Below_Water\": [\"ocean\", \"marine\", \"fishery\", \"plastic pollution\", \"海洋\", \"океан\", \"océano\"],\n",
        "    \"SDG15_Life_On_Land\": [\"biodiversity\", \"forest\", \"deforestation\", \"wildlife\", \"生物多样性\", \"лес\", \"biodiversidad\"],\n",
        "    \"SDG16_Peace_Justice\": [\"corruption\", \"justice\", \"conflict\", \"rule of law\", \"коррупц\", \"法治\", \"justicia\"],\n",
        "    \"SDG17_Partnerships\": [\"partnership\", \"multilateral\", \"UN\", \"SDGs\", \"cooperation\", \"партнерств\", \"合作\", \"alianzas\"],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote /Users/sergey/code/sdg-multilingual-media-narratives/sdg_keywords.json\n"
          ]
        }
      ],
      "source": [
        "# Save default SDG keywords to JSON for reuse/editing\n",
        "import json\n",
        "kw_path = os.path.join(PROJECT_DIR, 'sdg_keywords.json')\n",
        "with open(kw_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(SDG_KEYWORDS, f, ensure_ascii=False, indent=2)\n",
        "print('Wrote', kw_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5213f1b6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (jupyter-venv)",
      "language": "python",
      "name": "jupyter-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}